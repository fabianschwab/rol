# RedHat Learning

## Terminal

```bash
# create multiple directories with -p (parent) and print out each created directory with -v (verbose)
mkdir -pv /parent/child/childOfChild

# Grep ip address of host
ip -br addr list | grep eth0

# Podman listing with column variables
podman images --format "table {{.ID}} {{.Repository}} {{.Tag}}"
```

## Red Hat OpenShift I: Containers & Kubernetes

First things:

!!! danger Accounts
    see accounts in `.env.example` you need to create

!!! note Setup for class machine
    1. Credentials  
        User: Student  
        Password: student
    2. Git
        `git config --global credential.helper cache`
    3. Execute `lab-configure`

## Podman Basics

```bash
# Login
podman login <registry>

#Listing images
podman images ls
```

### Building

Naming of images with the `-t` tag flag. Use `<registry>/<username>/<image-name>:<version>` as naming convention for pushing images to registries.

```bash
podman build --layers=false -t quay.io/fabian_schwab_ibm/image:latest .
# --layers=false don't cache layers
```

### Starting Container

```bash
podman run -d -p 8080:80 --name httpd-basic quay.io/redhattraining/httpd-parent
# -d detached (in background)
# -p port outside to port inside
# --name no shorthand
# last is image name
```

### Go inside container

```bash
podman exec -it httpd-basic bin/bash
# Container name or id
```

### Copy file into container

```bash
podman cp ./test.md myContainer:/
# podman cp filepath container-name:path
```

## Mounting a Volume into Container

One way to set up the host directory is described below:

Create a directory:

`[user@host ~]$ mkdir /home/student/dbfiles`  
The user running processes in the container must be capable of writing files to the directory. The permission should be defined with the numeric user ID (UID) from the container. For the MySQL service provided by Red Hat, the UID is 27. The podman unshare command provides a session to execute commands within the same user namespace as the process running inside the container.

`[user@host ~]$ podman unshare chown -R 27:27 /home/student/dbfiles`  
Apply the container_file_t context to the directory (and all subdirectories) to allow containers access to all of its contents.

`[user@host ~]$ sudo semanage fcontext -a -t container_file_t '/home/student/dbfiles(/.*)?'`  
Apply the SELinux container policy that you set up in the first step to the newly created directory:

`[user@host ~]$ sudo restorecon -Rv /home/student/dbfiles`  
The host directory must be configured before starting the container that uses the directory.

`[user@host ~]$ podman run -v /home/student/dbfiles:/var/lib/mysql rhmap47/mysql`

## Docker, Container Files

!!! success
    `Containerfile` is the default name used by OCI compliant tools

### Structure

```yaml
# This is a comment line [1]
FROM ubi8/ubi:8.5 [2]
LABEL description="This is a custom httpd container image" [3]
MAINTAINER John Doe <jdoe@xyz.com> [4]
RUN yum install -y httpd [5]
EXPOSE 80 [6]
ENV LogLevel=info [7]
ADD http://someserver.com/filename.pdf /var/www/html [8]
COPY ./src/ /var/www/html/ [9]
USER apache [10]
ENTRYPOINT ["/usr/sbin/httpd"] [11]
CMD ["-D", "FOREGROUND"] [12]
```

1. Lines that begin with a hash, or pound, sign (#) are comments.
1. The `FROM` instruction declares that the new container image extends ubi8/ubi:8.5 container base image. Containerfiles can use any other container image as a base image, not only images from operating system distributions. Red Hat provides a set of container images that are certified and tested and highly recommends using these container images as a base.
1. The `LABEL` is responsible for adding generic metadata to an image. A `LABEL` is a simple key-value pair.
1. `MAINTAINER` indicates the Author field of the generated container image's metadata. You can use the podman inspect command to view image metadata.
1. `RUN` executes commands in a new layer on top of the current image. The shell that is used to execute commands is /bin/sh.
1. `EXPOSE` indicates that the container listens on the specified network port at runtime. The `EXPOSE` instruction defines metadata only; it does not make ports accessible from the host. The -p option in the podman run command exposes container ports from the host.
1. `ENV` is responsible for defining environment variables that are available in the container. You can declare multiple `ENV` instructions within the Containerfile. You can use the `env` command inside the container to view each of the environment variables.
1. `ADD` instruction copies files or folders from a local or remote source and adds them to the container's file system. If used to copy local files, those must be in the working directory. `ADD` instruction unpacks local .tar files to the destination image directory.
1. `COPY` copies files from the working directory and adds them to the container's file system. It is not possible to copy a remote file using its URL with this Containerfile instruction.
1. `USER` specifies the username or the UID to use when running the container image for the `RUN`, `CMD`, and `ENTRYPOINT` instructions. It is a good practice to define a different user other than root for security reasons.
1. `ENTRYPOINT` specifies the default command to execute when the image runs in a container. If omitted, the default `ENTRYPOINT` is /bin/sh -c.
1. `CMD` provides the default arguments for the `ENTRYPOINT` instruction. If the default `ENTRYPOINT` applies (/bin/sh -c), then `CMD` forms an executable command and parameters that run at container start.

But unlike `ARG`, you canâ€™t override `ENV` values directly from the commandline when building your image. However, you can use `ARG` values to dynamically set default values of `ENV` variables during the build like this:

```yaml
# You can set VAR_A while building the image
# or leave it at the default
ARG VAR_A=5
# VAR_B gets the (overridden) value of VAR_A
ENV VAR_B=${VAR_A}
```

!!! danger Warning
    Both the ADD and COPY instructions copy the files, retaining permissions, with root as the owner, even if the USER instruction is specified. Red Hat recommends using a RUN instruction after the copy to change the owner and avoid permission denied errors.

### Layering Image

To reduce to much image layers combine commands with `\` in `RUN` , `LABEL` or `ENV`. E.g:

```yaml
RUN yum --disablerepo=* --enablerepo="rhel-7-server-rpms" && \
    yum update -y && \
    yum install -y httpd

LABEL version="2.0" \
      description="This is an example container image" \
      creationDate="01-09-2017"

ENV MYSQL_ROOT_PASSWORD="my_password" \
    MYSQL_DATABASE "my_database"
```

### Additional Linux commands commonly used in Containerfiles

Installing packages in ubi8 images can be done with `yum`.  
For use in Containerfiles use `RUN <cmd>`.

```bash
# Use the y flag to automatically answer all questions
yum install -y <package name>

# Add the `clean` command to remove cached data
yum clean all -y

# Optional: do not install documentation
yum install --nodocs
```

Creating user and user groups as well as change the permissions

```bash
# 1. Adding a user group
groupadd -r -f <group_name> -g <uid>
# -r create a system account, 
# -f exits successfully is group already exists, 
# -g use specific group id for group

# 2. Adding a user to the group
useradd -u <uid> -r -g <group_name> -m -d <user_home_dir> -s /sbin/nologin -c "Comment" <user_name>
# -u use specific user id for new user
# -r create system account
# -g name or id of the user group for the user
# -m create users home directory
# -d path where home dir should be
# -s std login shell for the user
# -c comment

# 3. Change the ownership of the home dir of the user to the user itself
chown -R <user_name>:<group_name> <user_home_dir>
# 4. Set permissions to user (r,w,x), group (r,x) and other (r,x) 
chmod -R 755 <user_home_dir>
# -R is recursive for all nested files and folders
```

Creating links

```bash
# Links
ln -s <target> <link_name>
# -s Symbolic link instead of hard link
```

### Describing How to Use the OpenShift Source-to-Image Tool

Source-to-Image (S2I) provides an alternative to using Containerfiles to create new container images that can be used either as a feature from OpenShift or as the standalone s2i utility. S2I allows developers to work using their usual tools, instead of learning Containerfile syntax and using operating system commands such as yum. The S2I utility usually creates slimmer images with fewer layers.

S2I uses the following process to build a custom container image for an application:

1. Start a container from a base container image called the builder image. This image includes a programming language runtime and essential development tools, such as compilers and package managers.
1. Fetch the application source code, usually from a Git server, and send it to the container.
1. Build the application binary files inside the container.
1. Save the container, after some clean up, as a new container image, which includes the programming language runtime and the application binaries.

The builder image is a regular container image following a standard directory structure and providing scripts that are called during the S2I process. Most of these builder images can also be used as base images for Containerfiles, outside of the S2I process.

The s2i command is used to run the S2I process outside of OpenShift, in a Docker-only environment. It can be installed on a RHEL system from the source-to-image RPM package, and on other platforms, including Windows and Mac OS, from the installers available in the S2I project on GitHub.

#### In a Nutshell

- Build step: Responsible for compiling source code, downloading library dependencies, and packaging the application as a container image. Furthermore, the build step pushes the image to the OpenShift registry for the deployment step. The BuildConfig (BC) OpenShift resources drive the build step.
- Deployment step: Responsible for starting a pod and making the application available for OpenShift. This step executes after the build step, but only if the build step succeeded. The Deployment OpenShift resources drive the deployment step.

## OpenShift Deployments

An OpenShift cluster is a Kubernetes cluster that can be managed the same way, but using the management tools provided by OpenShift, such as the command-line interface or the web console. This allows for more productive workflows and makes common tasks much easier.

### Kubernetes Resource Types

- Pods (po)
- Services (svc)
- Replication Controllers (rc)
- Persistent Volumes (pv)
- Persistent Volume Claims (pvc)
- ConfigMaps (cm) and Secrets
    Contains a set of keys and values that can be used by other resources. ConfigMaps and Secrets are usually used to centralize configuration values used by several resources. Secrets differ from ConfigMaps maps in that Secrets' values are always encoded (not encrypted) and their access is restricted to fewer authorized users.

### OpenShift Resource Types

- Deployment and Deployment config (dc)
- Build config (bc)  
    Defines a process to be executed in the OpenShift project. Used by the OpenShift Source-to-Image (S2I) feature to build a container image from application source code stored in a Git repository.
- Routes  
    To expose a service outside a cluster

### Templates

Processing a Template Using the CLI

```bash
oc process

# Prints out into stdout. Can be redirected into a file to apply
oc process -o yaml -f filename  > result.yaml

# Use the -p flag to pass in parameter
oc process -o yaml -f mysql.yaml -p MYSQL_USER=dev \
-p MYSQL_PASSWORD=$P4SSD -p MYSQL_DATABASE=bank \
-p VOLUME_CAPACITY=10Gi > mysqlProcessed.yaml
```

Instead of redirecting the output into a file, its possible to pipe it directly to the `oc create` command like: `... | oc create -f -`

You can also use two slashes (//) to provide the namespace as part of the template name:

```bash
oc process openshift//mysql-persistent \
-p MYSQL_USER=dev -p MYSQL_PASSWORD=$P4SSD -p MYSQL_DATABASE=bank \
-p VOLUME_CAPACITY=10Gi | oc create -f -
```

## Troubleshooting Containerized Applications

### S2I

The S2I process starts each step in a separate pod. The build process creates a pod named `<application-name>-build-<number>-<string>`.
For each build attempt, the entire build step executes and saves a log. Upon a successful build, the application starts on a separate pod named as `<application-name>-<string>`.

- Retrieve the logs from a build configuration `oc logs bc/<application-name>`
- Rerun a build `oc start-build <application-name>`
- Deployment logs can be checked with `oc logs deployment/<application-name>`

### Permissions

OpenShift default security rule is that every pod runs with a random user id and no `root` is available which leads to restrictions of system resources.

To solve issues with users use the `oc adm` command.

```bash
oc adm policy add-scc-to-user anyuid -z default
```

To avoid **file system permission issues**, local folders used for container volume mounts must satisfy the following:

- The user executing the container processes must be the owner of the folder, or have the necessary rights. Use the chown command to update folder ownership.
- The local folder must satisfy the SELinux requirements to be used as a container volume. Assign the container_file_t group to the folder by using the semanage fcontext -a -t container_file_t `<folder>` command, then refresh the permissions with the restorecon -R `<folder>` command.

### Troubleshooting Invalid Parameters

Best practice to store parameters are environment variables via `Secrets` or `ConfigMaps` and inject them into the `yaml` file in the `env` section.

### Troubleshooting Volume Mount Errors

To resolve the issue, delete the persistent volume claim and then the persistent volume. Then recreate the persistent volume.

### Troubleshooting Obsolete Images

Run the `oc adm prune` command for an automated way to remove obsolete images and other resources.

### Forwarding Ports for Troubleshooting

The `oc port-forward <type> <local_port> <remote_port>` command maps a forwards connection to a single pod. Type can be anything like service, pod, deployment ... `pod/<pod_name>`

### OpenShift Events

OpenShift provides a high-level logging tool called Events `oc get events`. For events for a specific pod run `oc describe pod <pod_name>`

## Sources

- [RedHat Container Registry](https://catalog.redhat.com/)
